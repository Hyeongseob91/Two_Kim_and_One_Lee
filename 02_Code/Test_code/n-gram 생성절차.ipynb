{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n-그램을 생성할 때, 파이썬에서는 **내장된 예약어**와 **외부 모듈**을 혼합해서 사용할 수 있습니다. 어떤 방식을 선택할지는 프로젝트의 복잡도와 요구사항에 따라 달라집니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **내장된 예약어로만 진행**\n",
    "내장된 예약어(`for` 루프, 리스트 컴프리헨션 등)를 활용하면 다음과 같이 진행할 수 있습니다.\n",
    "\n",
    "#### 예제 코드\n",
    "```python\n",
    "def generate_ngrams(text, n):\n",
    "    tokens = text.split()  # 단어 단위로 분리\n",
    "    ngrams = [tuple(tokens[i:i + n]) for i in range(len(tokens) - n + 1)]\n",
    "    return ngrams\n",
    "```\n",
    "\n",
    "#### 장점\n",
    "- **모듈 설치 필요 없음**: 모든 작업이 기본 파이썬 기능으로 가능.\n",
    "- **직접 제어 가능**: n-그램 생성 과정을 세밀히 커스터마이즈 가능.\n",
    "\n",
    "#### 단점\n",
    "- **코드 작성의 복잡성**: 일부 고급 분석(예: 빈도 계산, TF-IDF 등)을 구현하려면 추가적인 코드가 필요.\n",
    "- **효율성 부족**: 큰 데이터셋에서는 처리 속도가 느릴 수 있음.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **외부 모듈을 활용한 방법**\n",
    "외부 모듈을 활용하면 더 간단하고 효율적으로 n-그램을 생성할 수 있습니다. 대표적으로 사용하는 모듈은 다음과 같습니다.\n",
    "\n",
    "#### (1) **`nltk`** 모듈\n",
    "`nltk`는 자연어 처리를 위한 강력한 라이브러리로, n-그램 생성을 포함해 다양한 기능을 제공합니다.\n",
    "\n",
    "##### 예제 코드\n",
    "```python\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# n-그램 생성\n",
    "text = \"나는 너를 사랑해 너는 나를 사랑해 나는 노래를 부른다\"\n",
    "tokens = text.split()\n",
    "n = 2  # 2-그램 생성\n",
    "ngrams_result = list(ngrams(tokens, n))\n",
    "print(ngrams_result)\n",
    "# 출력: [('나는', '너를'), ('너를', '사랑해'), ('사랑해', '너는'), ('너는', '나를'),\n",
    "#       ('나를', '사랑해'), ('사랑해', '나는'), ('나는', '노래를'), ('노래를', '부른다')]\n",
    "```\n",
    "\n",
    "#### 장점\n",
    "- **간결한 코드**: n-그램 생성을 단 한 줄로 처리 가능.\n",
    "- **다양한 기능 지원**: 텍스트 전처리, 토큰화, 품사 태깅 등과 결합 가능.\n",
    "\n",
    "#### 단점\n",
    "- 추가 설치 필요:\n",
    "  ```bash\n",
    "  pip install nltk\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "#### (2) **`sklearn`** 모듈\n",
    "`scikit-learn`은 머신러닝 중심 라이브러리지만, `CountVectorizer` 또는 `TfidfVectorizer`를 활용하면 n-그램을 쉽게 생성할 수 있습니다.\n",
    "\n",
    "##### 예제 코드\n",
    "```python\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = [\"나는 너를 사랑해 너는 나를 사랑해 나는 노래를 부른다\"]\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2))  # 2-그램\n",
    "ngrams = vectorizer.fit_transform(text)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "# 출력: ['나는 노래를' '나는 너를' '너를 사랑해' '너는 나를' '노래를 부른다' '나를 사랑해' '사랑해 나는' '사랑해 너는']\n",
    "```\n",
    "\n",
    "#### 장점\n",
    "- **n-그램과 빈도 계산을 동시에 처리**: 생성된 n-그램의 빈도를 바로 확인 가능.\n",
    "- **TF-IDF 지원**: 가사 데이터의 중요도에 따른 가중치 계산 가능.\n",
    "\n",
    "#### 단점\n",
    "- 추가 설치 필요:\n",
    "  ```bash\n",
    "  pip install scikit-learn\n",
    "  ```\n",
    "- 단어 단위 분석이 기본. 문자 단위 분석은 추가 설정 필요.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **선택 기준**\n",
    "#### **내장된 예약어 사용**\n",
    "- 소규모 데이터셋.\n",
    "- 단순한 n-그램 생성이 목표.\n",
    "- 외부 라이브러리 설치를 피하고 싶은 경우.\n",
    "\n",
    "#### **외부 모듈 사용**\n",
    "- 대규모 데이터셋 처리.\n",
    "- 빈도 계산, TF-IDF 가중치 등 추가 분석 필요.\n",
    "- 다른 자연어 처리 작업과 결합 가능성 고려.\n",
    "\n",
    "---\n",
    "\n",
    "### 추천\n",
    "- 프로젝트 초기 단계나 단순한 분석은 내장된 예약어만 사용.\n",
    "- 추가적인 분석과 대규모 데이터 처리에는 `nltk`나 `sklearn` 같은 외부 모듈 활용을 추천."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
