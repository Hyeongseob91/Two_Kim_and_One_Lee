{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문장생성 테스트 \n",
    "* 마르코프 체인\n",
    "* LSTM/RNN\n",
    "\n",
    "https://jeongminhee99.tistory.com/81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 마르코프 체인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "from konlpy.tag import Twitter\n",
    "import urllib.request\n",
    "import os, re, json, random\n",
    "\n",
    "#네이버 맞춤법 검사 요청에 user-agent 헤더 추가\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 마르코프 체인 딕셔너리 만들기 \n",
    "* 마르고프 체인 전용 사전을 만든다. \n",
    "* 이 사전은 파이썬 딕셔너리 자료형이며 이전에 설명했던 것처럼 세 단어가 한 세트이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마르코프 체인 딕셔너리 만들기\n",
    "def make_dic(words):\n",
    "    tmp = [\"@\"]\n",
    "    dic = {}\n",
    "    for word in words:\n",
    "        tmp.append(word)\n",
    "        if len(tmp) < 3: continue\n",
    "        if len(tmp) > 3: tmp = tmp[1:]\n",
    "        set_word3(dic, tmp)\n",
    "        if word == \".\":\n",
    "            tmp = [\"@\"]\n",
    "            continue\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 딕셔너리에 데이터 등록하기 \n",
    "* 딕셔너리에 데이터를 등록한다. \n",
    "* 이때 문장의 시작을 나타내는 부분을 \"@'로 나타내었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딕셔너리에 데이터 등록하기 --- (※2)\n",
    "def set_word3(dic, s3):\n",
    "    w1, w2, w3 = s3\n",
    "    if not w1 in dic: dic[w1] = {}\n",
    "    if not w2 in dic[w1]: dic[w1][w2] = {}\n",
    "    if not w3 in dic[w1][w2]: dic[w1][w2][w3] = 0\n",
    "    dic[w1][w2][w3] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 문장 만들기 \n",
    "* 여기서는 문장을 만든다. \n",
    "* 마르코프 체인의 사전에는 이어서 사용할 수 있는 후보들이 저장되어 있으므로 \n",
    "* 무작위 후보들을 하나씩 꺼내서 연결하면 나름 그럴듯한 문장이 만들어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 만들기 --- (※3)\n",
    "def make_sentence(dic):\n",
    "    ret = []\n",
    "    if not \"@\" in dic: return \"no dic\" \n",
    "    top = dic[\"@\"]\n",
    "    w1 = word_choice(top)\n",
    "    w2 = word_choice(top[w1])\n",
    "    ret.append(w1)\n",
    "    ret.append(w2)\n",
    "    while True:\n",
    "        w3 = word_choice(dic[w1][w2])\n",
    "        ret.append(w3)\n",
    "        if w3 == \".\": break\n",
    "        w1, w2 = w2, w3\n",
    "    ret = \"\".join(ret)\n",
    "    # 띄어쓰기\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"_callback\": \"\",\n",
    "        \"q\": ret\n",
    "    })\n",
    "    # 네이버 맞춤법 검사기를 사용합니다.\n",
    "    # data = urllib.request.urlopen(\"https://m.search.naver.com/p/csearch/ocontent/util/SpellerProxy?\" + params)\n",
    "    data = urllib.request.urlopen(\"https://m.search.naver.com/p/csearch/ocontent/spellchecker.nhn?\" + params)\n",
    "    data = data.read().decode(\"utf-8\")[1:-2]\n",
    "    data = json.loads(data)\n",
    "    data = data[\"message\"][\"result\"][\"html\"]\n",
    "    data = soup = BeautifulSoup(data, \"html.parser\").getText()\n",
    "    # 리턴\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 데이터 학습 및 가공 \n",
    "* 텍스트를 읽고, 간단하게 가공한다. \n",
    "* 형태소 분석을 하고 마르코프 체인을 위한 딕셔너리를 생성한 뒤 JSON 파일로 저장한다.\n",
    "* 딕셔너리를 기반으로 문장을 생성해서 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "# C:\\Two_Kim_and_One_Lee\\01_data_모음\\melon.csv\n",
    "songs = pd.read_csv(\"../01_data_모음/melon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노래 가사 리스트를 가져옴\n",
    "songlist = list(songs['lylics'])  # 오타임.. \n",
    "txtsongs = \"\"\n",
    "\n",
    "# 각 노래 가사를 하나의 문자열로 합침\n",
    "for song in songlist:\n",
    "    txtsongs += song + \"\\n\"  # 각 노래 뒤에 줄바꿈 추가\n",
    "\n",
    "# 파일에 저장\n",
    "with open('../01_data_모음/melon5000test.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(txtsongs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeError",
     "evalue": "UTF-16 stream does not start with BOM",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(dict_file):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# 텍스트 파일 읽어 들이기\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     fp \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../01_data_모음/melon5000test.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-16\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m     soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhtml.parser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     body \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mselect_one(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody > text\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m     text \u001b[38;5;241m=\u001b[39m body\u001b[38;5;241m.\u001b[39mgetText()\n",
      "File \u001b[1;32mc:\\Two_Kim_and_One_Lee\\.env311\\Lib\\site-packages\\bs4\\__init__.py:314\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only \u001b[38;5;241m=\u001b[39m parse_only\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(markup, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):        \u001b[38;5;66;03m# It's a file-type object.\u001b[39;00m\n\u001b[1;32m--> 314\u001b[0m     markup \u001b[38;5;241m=\u001b[39m \u001b[43mmarkup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(markup) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    316\u001b[0m         (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[0;32m    317\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;66;03m# Beautiful Soup will still parse the input as markup,\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;66;03m# since that is sometimes the intended behavior.\u001b[39;00m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_markup_is_url(markup):\n",
      "File \u001b[1;32m<frozen codecs>:707\u001b[0m, in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n",
      "File \u001b[1;32m<frozen codecs>:507\u001b[0m, in \u001b[0;36mread\u001b[1;34m(self, size, chars, firstline)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\encodings\\utf_16.py:141\u001b[0m, in \u001b[0;36mStreamReader.decode\u001b[1;34m(self, input, errors)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mutf_16_be_decode\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m consumed\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUTF-16 stream does not start with BOM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mobject\u001b[39m, consumed)\n",
      "\u001b[1;31mUnicodeError\u001b[0m: UTF-16 stream does not start with BOM"
     ]
    }
   ],
   "source": [
    "def word_choice(sel):\n",
    "    keys = sel.keys()\n",
    "    return random.choice(list(keys))\n",
    "\n",
    "# 문장 읽어 들이기 --- (※4)\n",
    "toji_file = \"melon_file\"\n",
    "dict_file = \"markov-melon.json\"\n",
    "if not os.path.exists(dict_file):\n",
    "    # 텍스트 파일 읽어 들이기\n",
    "    fp = codecs.open(\"../01_data_모음/melon5000test.txt\", \"r\", encoding=\"utf-16\")\n",
    "    soup = BeautifulSoup(fp, \"html.parser\")\n",
    "    body = soup.select_one(\"body > text\")\n",
    "    text = body.getText()\n",
    "    text = text.replace(\"…\", \"\") # 현재 koNLPy가 …을 구두점으로 잡지 못하는 문제 임시 해결\n",
    "    # 형태소 분석\n",
    "    # twitter = Twitter()\n",
    "    twitter=Twitter()\n",
    "    malist = twitter.pos(text, norm=True)\n",
    "    words = []\n",
    "    for word in malist:\n",
    "        # 구두점 등은 대상에서 제외(단 마침표는 포함)\n",
    "        if not word[1] in [\"Punctuation\"]:\n",
    "            words.append(word[0])\n",
    "        if word[0] == \".\":\n",
    "            words.append(word[0])\n",
    "    # 딕셔너리 생성\n",
    "    dic = make_dic(words)\n",
    "    json.dump(dic, open(dict_file,\"w\", encoding=\"utf-8\"))\n",
    "else:\n",
    "    dic = json.load(open(dict_file,\"r\"))\n",
    "# 문장 만들기 --- (※6)\n",
    "for i in range(3):\n",
    "    s = make_sentence(dic)\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
